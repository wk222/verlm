#!/bin/bash
# GSPO Training - Qwen3-1.7B on WZX MATH Dataset
# GSPO = GRPO + å¥çº§æ¦‚ç‡ (Sentence-level Probability)
# å‚è€ƒè®ºæ–‡: https://arxiv.org/pdf/2507.18071
# Optimized for 4x4090 (24GB VRAM each)

set -e

echo "=========================================="
echo "GSPO Training - Qwen3 on 4x4090"
echo "=========================================="
echo ""

# Check if we're in the verlm directory
if [ ! -d "verl/trainer" ]; then
    echo "âŒ Error: Please run this script from the verlm/ directory."
    echo "   Current directory: $(pwd)"
    exit 1
fi

# Set environment variables
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
export CUDA_VISIBLE_DEVICES=0,1,2,3

# Configuration
CONFIG_NAME="gspo_qwen3_math_hybrid"
OUTPUT_DIR="data/Qwen3-1.7B-GSPO-WZX"
DATA_DIR="data/math_level3"
N_GPUS=4

echo "Configuration:"
echo "  - Config: ${CONFIG_NAME}"
echo "  - Output: ${OUTPUT_DIR}"
echo "  - Data: ${DATA_DIR}"
echo "  - GPUs: ${CUDA_VISIBLE_DEVICES} (${N_GPUS} GPUs)"
echo "  - Algorithm: GSPO (GRPO + Sentence-level Probability)"
echo ""

# Download and preprocess MATH Level3 dataset if not exists
if [ ! -f "${DATA_DIR}/train.parquet" ]; then
    echo "ğŸ“¥ Downloading and preprocessing MATH Level3 dataset..."
    python3 examples/data_preprocess/math_level3_dataset.py \
        --local_save_dir ${DATA_DIR}
    echo ""
else
    echo "âœ… MATH Level3 dataset already exists at ${DATA_DIR}"
    echo ""
fi

echo "ğŸš€ Starting GSPO training..."
echo ""

# ============================================================
# GSPO å…¨åºåˆ—çº§ä¼˜åŒ–ç‰ˆé…ç½®è¯´æ˜:
# ============================================================
# æ ¸å¿ƒä¼˜åŒ–: ä» Advantage Estimator åˆ° Policy Loss å…¨ç¨‹åºåˆ—çº§åˆ«è®¡ç®—
#
# 1. adv_estimator: grpo_seq (åºåˆ—çº§GRPOï¼Œè¿”å› (B,) è€Œé (B,T))
#    - åŸç‰ˆ grpo è¿”å› (B, T) å¼ é‡ï¼Œæ¯ä¸ªtokenå¤åˆ¶ç›¸åŒadvantageå€¼
#    - grpo_seq è¿”å› (B,) å¼ é‡ï¼Œç›´æ¥æ˜¯åºåˆ—çº§åˆ«
#    - æ˜¾å­˜èŠ‚çœ: advantages ä» B*T â†’ B (ä¾‹: 512*1280 â†’ 512)
#
# 2. policy_loss.loss_mode: gspo (è‡ªåŠ¨æ£€æµ‹ç»´åº¦ï¼Œé€‰æ‹©æœ€ä¼˜è·¯å¾„)
#    - å½“ advantages æ˜¯ (B,) æ—¶ï¼šå…¨ç¨‹åºåˆ—çº§è®¡ç®—ï¼Œé«˜æ•ˆ
#    - å½“ advantages æ˜¯ (B,T) æ—¶ï¼šå›é€€åˆ°tokençº§è®¡ç®—ï¼Œå…¼å®¹
#    - ä¸ grpo_seq é…åˆä½¿ç”¨æ—¶ï¼Œæ€§èƒ½ä¸ ADPO ç›¸å½“
#
# 3. æ€§èƒ½æå‡ (grpo_seq + gspo):
#    - æ˜¾å­˜: ä¸ ADPO ç›¸å½“ (advantages ä» B*T â†’ B)
#    - é€Ÿåº¦: å‘é‡åŒ–æ“ä½œï¼Œæ— Pythonå¾ªç¯
#    - åå: å¯ä»¥ä½¿ç”¨æ›´å¤§çš„ micro_batch_size
#
# 4. clip_ratio_high: 0.28 (GSPOè®ºæ–‡æ¨èçš„éå¯¹ç§°è£å‰ª)
# ============================================================

python -m verl.trainer.main_ppo \
    --config-name ${CONFIG_NAME} \
    data.train_files=${DATA_DIR}/train.parquet \
    data.val_files=${DATA_DIR}/train.parquet \
    trainer.n_gpus_per_node=${N_GPUS} \
    trainer.default_local_dir=${OUTPUT_DIR} \
    "$@"

echo ""
echo "=========================================="
echo "âœ… GSPO Training Complete!"
echo "=========================================="
