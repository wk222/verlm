max_response_length=1280	⭐⭐⭐⭐⭐	⭐⭐⭐⭐⭐	影响最大！序列长度直接影响 KV Cache 和激活显存
max_prompt_length=880	⭐⭐⭐⭐	⭐⭐⭐⭐	与 response_length 类似，但通常较短
gpu_memory_utilization=0.45	⭐⭐⭐⭐	⭐⭐⭐	vLLM KV Cache 预分配比例，直接控制 rollout 显存
rollout.n=8	⭐⭐⭐⭐	⭐⭐⭐⭐	每个 prompt 生成 n 个响应，显存和计算量线性增长
train_batch_size=128	⭐⭐⭐	⭐⭐⭐⭐	总体批次大小，通过梯度累积分摊
ppo_mini_batch_size=64	⭐⭐⭐	⭐⭐⭐	每次更新的样本数，影响梯度累积步数
ppo_micro_batch_size_per_gpu=8	⭐⭐	⭐⭐	单 GPU 前向/反向批次，降低可减少训练峰值显存
log_prob_micro_batch_size_per_gpu=8	⭐⭐	⭐	log prob 计算批次，仅影响该阶段显存
max_num_seqs=192	⭐⭐	⭐⭐	vLLM 并发序列数，影响 rollout 调度
fsdp_config.param_offload=False	⭐⭐⭐	⭐⭐⭐	开启可大幅降低显存，但显著降速
enforce_eager=False	⭐	⭐⭐	True 禁用 CUDA Graph，降显存但降速
enable_chunked_prefill=True	⭐	⭐	分块 prefill，略微降显存
enable_prefix_caching=True	⭐	⭐⭐	前缀缓存，可能加速重复 prompt
free_cache_engine=True	⭐⭐	⭐	rollout 后释放 KV Cache，降显存但有重建开销